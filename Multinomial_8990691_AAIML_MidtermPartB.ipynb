{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940afc79",
   "metadata": {},
   "source": [
    "### **Name** : Manu Mathew\n",
    "### **Student Id**: 8990691"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86426d8e",
   "metadata": {},
   "source": [
    "1. Use wine dataset from sklearn.datasets to classify wines into 3 categories. Load the dataset and split it into test and train. Train the model using Gaussian and Multinominal classifiers and post which model performs better. Use the trained model to perform some predictions on test data.\n",
    "\n",
    "   Record your observations/reflections in the Python notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34258f26",
   "metadata": {},
   "source": [
    "# (Optional) Install libraries, if not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas scikit-learn jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c40966",
   "metadata": {},
   "source": [
    "# Load the wine dataset which is a classic dataset for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "theWine = load_wine()\n",
    "# Features or the columns\n",
    "Xfeatures = theWine.data\n",
    "# Target variables\n",
    "Ytarget = theWine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77bfd4",
   "metadata": {},
   "source": [
    "# Convert to the Dataframe for visualizing the data structures and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Xfeatures, columns = theWine.feature_names)\n",
    "df['target'] = Ytarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data sets loaded sucessfully \\n\")\n",
    "print(\"Wine Shape of features:\", Xfeatures.shape, \"Shape of target:\", Ytarget.shape)\n",
    "print(\"\\nDisplaying first 5 rows of the dataset:\")\n",
    "print(df.head(5))\n",
    "print(\"\\nChecking for null or empty values\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTarget names:\", theWine.target_names)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c77952",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the dataset into training and testing sets.\n",
    "X_train, y_train --> data used to train the model.\n",
    "X_test, y_test --> data used to evaluate the model's performance.\n",
    "test_size=0.3 means 30% of the data will be used for testing.\n",
    "random_state ensures reproducibility of the split.\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xfeatures, Ytarget, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"\\nThe Data Splitting phase:\")\n",
    "print(f\"The Data split into training (X_train: {X_train.shape}, y_train: {y_train.shape})\")\n",
    "print(f\"and Testing (X_test: {X_test.shape}, y_test: {y_test.shape}) sets.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcc597",
   "metadata": {},
   "source": [
    "# Train Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46038e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Gaussian Naive Bayes\")\n",
    "# Initializing the Gaussian Naive Bayes classifier.\n",
    "gaussian_m = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a0d4c",
   "metadata": {},
   "source": [
    "# Train the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5262ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe11f6",
   "metadata": {},
   "source": [
    "# Make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_predictions = gaussian_m.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb2423",
   "metadata": {},
   "source": [
    "# Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dea983",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_accuracy = accuracy_score(y_test, gaussian_predictions)\n",
    "print(f\"The Accuracy for Gaussian Naive Bayes: {gaussian_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c584e",
   "metadata": {},
   "source": [
    "# Print a detailed classification report, including precision, recall, and f1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60336d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report for Gaussian Naive Bayes:\")\n",
    "print(classification_report(y_test, gaussian_predictions, target_names=theWine.target_names))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f7b44",
   "metadata": {},
   "source": [
    "# Train Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf69e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Training Multinomial Naive Bayes\")\n",
    "# Initialize the Multinomial Naive Bayes classifier.\n",
    "multinomial_mo = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a88a1",
   "metadata": {},
   "source": [
    "# Train the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26422f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_mo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114b74c",
   "metadata": {},
   "source": [
    "# Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_predictions = multinomial_mo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507d900",
   "metadata": {},
   "source": [
    "# Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_accuracy = accuracy_score(y_test, multinomial_predictions)\n",
    "print(f\"Multinomial Naive Bayes Accuracy: {multinomial_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f66089",
   "metadata": {},
   "source": [
    "# Print a detailed classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report for Multinomial Naive Bayes:\")\n",
    "print(classification_report(y_test, multinomial_predictions, target_names=theWine.target_names))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb749f",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Comparison:\")\n",
    "# Comparing the accuracy of the two models.\n",
    "if gaussian_accuracy > multinomial_accuracy:\n",
    "    print(f\"Gaussian Naive Bayes performed better with an accuracy of {gaussian_accuracy:.4f} \"\n",
    "          f\"compared to Multinomial Naive Bayes' accuracy of {multinomial_accuracy:.4f}.\")\n",
    "    best_model = gaussian_m\n",
    "    best_model_name = \"Gaussian Naive Bayes\"\n",
    "else:\n",
    "    print(f\"Multinomial Naive Bayes performed better** with an accuracy of {multinomial_accuracy:.4f} \"\n",
    "          f\"compared to Gaussian Naive Bayes' accuracy of {gaussian_accuracy:.4f}.\")\n",
    "    best_model = multinomial_mo\n",
    "    best_model_name = \"Multinomial Naive Bayes\"\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b606e5",
   "metadata": {},
   "source": [
    "# Predictions on test data using the better model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d379e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPerforming Predictions using the {best_model_name} model\")\n",
    "# Select a small subset of the test data to demonstrate predictions.\n",
    "num_of_predictions_to_show = 5\n",
    "sample_X_test = X_test[:num_of_predictions_to_show]\n",
    "sample_y_test = y_test[:num_of_predictions_to_show]\n",
    "\n",
    "# Get predictions from the best performing model.\n",
    "sample_predictions = best_model.predict(sample_X_test)\n",
    "\n",
    "print(f\"\\nFirst {num_of_predictions_to_show} actual labels (0=class_0, 1=class_1, 2=class_2):\")\n",
    "print(sample_y_test)\n",
    "print(f\"First {num_of_predictions_to_show} predicted labels by {best_model_name}:\")\n",
    "print(sample_predictions)\n",
    "\n",
    "print(\"\\nDetailed comparison for the first few samples:\")\n",
    "for i in range(num_of_predictions_to_show):\n",
    "    actual_class_name = theWine.target_names[sample_y_test[i]]\n",
    "    predicted_class_name = theWine.target_names[sample_predictions[i]]\n",
    "    print(f\"Sample {i+1}: Actual: {actual_class_name} (Label: {sample_y_test[i]}), \"\n",
    "          f\"Predicted: {predicted_class_name} (Label: {sample_predictions[i]})\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61fd86",
   "metadata": {},
   "source": [
    "# Record Observations/Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbc92d",
   "metadata": {},
   "source": [
    "### 7. Observations/Reflections\n",
    "\n",
    "1. **Data Loading and Splitting**: The wine dataset was loaded successfully and was then split into training and testing sets. The features or columns are all numerical and non-negative, making them suitable for both Gaussian and Multinomial Naive Bayes classifiers.\n",
    "\n",
    "2. **Gaussian Naive Bayes Performance**: Gaussian Naive Bayes performed very well on this dataset and the accuracy was higher 1.0000.\n",
    "\n",
    "3. **Multinomial Naive Bayes Performance**: Multinomial Naive Bayes, while applicable to non-negative continuous data, generally performed slightly worse than Gaussian Naive Bayes for this specific dataset. This is often because Multinomial Naive Bayes is inherently designed for discrete count data and while it can be adapted, it might not capture the nuances of continuous, non-count data as effectively as Gaussian Naive Bayes which explicitly models continuous distributions.\n",
    "\n",
    "4. **Model Comparison**: For the wine dataset, **Gaussian Naive Bayes proved to be the superior model** in terms of accuracy. \n",
    "\n",
    "5. **Predictions**: The better-performing model (Gaussian Naive Bayes in this case) demonstrated good predictive capability on unseen test data, correctly classifying most of the sample predictions shown.\n",
    "\n",
    "6. **Choosing the Right Naive Bayes Variant**: This exercise underscores the importance of considering the nature of your features when selecting a Naive Bayes algorithm. For continuous data, `GaussianNB` is generally the more appropriate choice, whereas for discrete count data, `MultinomialNB` is typically preferred.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
